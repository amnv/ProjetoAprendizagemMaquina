{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class Nbdos:\n",
    "\t\n",
    "    def __init__(self):\n",
    "        self.hck = {}\n",
    "\n",
    "    def list_neighbor(self, data, sfs, xi, k):\n",
    "        neigh = NearestNeighbors(n_neighbors=k)\n",
    "        neigh.fit(data.iloc[sfs, :data.shape[1]], data.iloc[sfs, -1])\n",
    "        return neigh.kneighbors([xi], return_distance=False).tolist()[0]\n",
    "\n",
    "    def nbdos(self, data, sc, k, k2_neighbors, rTh, nTh):\n",
    "        sfs = []\n",
    "        cl = [0] * sc.shape[0]\n",
    "        #print(\"aqui foi\")\n",
    "        return cl\n",
    "\n",
    "        # for indeces, xi in sc.iterrows():\n",
    "        #     tem = [a for a in self.list_neighbor(data, k2_neighbors, xi, k) if data.iloc[a, -1] == xi.iloc[-1]]\n",
    "        #     #print(indeces)\n",
    "        #     #print(len(tem))\n",
    "        #     if round(len(tem)/k) >= rTh:\n",
    "        #         print(\"Nem se quer aqui\")\n",
    "        #         sfs.append(indeces)\n",
    "        #         self.hck[indeces] = tem\n",
    "        \n",
    "        # for xi in sfs:\n",
    "        #     tem = self.list_neighbor(sfs, xi, cl, k)\n",
    "        #     print(\"passa aqui\")\n",
    "        #     if xi in self.hck.keys():\n",
    "        #         self.hck[xi].append(tem)\n",
    "        #     else:\n",
    "        #         self.hck[xi] = tem\n",
    "\n",
    "        # #print(list(sfs))\n",
    "        # curld = 0\n",
    "        # for xi in sfs:\n",
    "        #     if cl[xi] == 0:\n",
    "        #         curld += 1\n",
    "        #         self.expand_cluster(sfs, xi, cl, curld) #voltar a partir daqui\n",
    "\n",
    "        # for i in range(curld):\n",
    "        #     ci = [x for x in range(len(cl)) if cl[x] == i]\n",
    "        #     #ci = [xi for j, xi in sc.iterrows() if cl == i]\n",
    "\n",
    "        #     if len(ci) < nTh:\n",
    "        #         for j in ci:\n",
    "        #             cl[j] = 0\n",
    "        \n",
    "        # return cl \n",
    "    \n",
    "    def expand_cluster(self, sfsc, xi, cl, curld):\n",
    "        sfC = [xi]\n",
    "        cl[xi] = curld\n",
    "\n",
    "        # Check if list is empty\n",
    "        while sfC:\n",
    "            xj = sfC.__getitem__(-1)\n",
    "            for xl in self.hck[xj]:\n",
    "                if xl.cl == 0:\n",
    "                    xl.cl = curld\n",
    "                    if xl in sfsc:\n",
    "                        sfC.append(xi)\n",
    "\n",
    "            sfC.remove(xj)\n",
    "        return cl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import math\n",
    "import numpy\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class Instance:\n",
    "\n",
    "    def __init__(self, label):\n",
    "        # tuple key where key is the neighbor and the value is the selection weight\n",
    "        self.neighbors = {}\n",
    "        self.nk1 = {}\n",
    "        self.Fs_Fd = {}\n",
    "        self.cl = 0\n",
    "        self.label = label\n",
    "\n",
    "    def set_fs_fd(self, fs):\n",
    "        self.Fs_Fd = fs\n",
    "\n",
    "    def get_fs(self):\n",
    "        return list(self.Fs_Fd.keys())\n",
    "\n",
    "    def get_fd(self):\n",
    "        return list(self.Fs_Fd.values())\n",
    "\n",
    "    def get_nk1(self):\n",
    "        return self.nk1.keys()\n",
    "\n",
    "    def add_neighbor(self, neighbor):\n",
    "        self.neighbors[neighbor] = 0\n",
    "\n",
    "    def get_list_neighbor(self):\n",
    "        return list(self.neighbors.keys())\n",
    "\n",
    "    def get_neighbor_weight(self, neighbor):\n",
    "        return self.neighbors[neighbor]\n",
    "\n",
    "    def get_neighbor_high_weight(self):\n",
    "        return max(self.neighbors, key=self.neighbors.get)\n",
    "\n",
    "    def set_selection_weight(self, key, w1):\n",
    "        self.neighbors[key] = (1 + w1)/math.e\n",
    "\n",
    "    @staticmethod\n",
    "    def ss(xi, xj, fs_fd):\n",
    "        \"\"\"Step 5.3 article\n",
    "            :return list of neighbors Fs which the distance is no longer than\n",
    "            the distance between this instance and the parameter\n",
    "        \"\"\"\n",
    "        threshold = numpy.linalg.norm(xi - xj)\n",
    "        return list({k: v for k, v in fs_fd.items() if numpy.linalg.norm(xi-v) > threshold}.keys())\n",
    "\n",
    "    @staticmethod\n",
    "    def dpn(pri, ari, ss, data):\n",
    "        \"\"\"\n",
    "        Used to find the instances set, NPN , which belong to the PN neighborhood xi.P N(xj)\n",
    "        Step 5.3 article + supplementary material\n",
    "        :param pri: primary reference instance (xi)\n",
    "        :param ari: assistant reference instance (xj)\n",
    "        :param ss: returned set from function ss\n",
    "        :return: the Npn: the set of instances in a radius distance from xi and xj\n",
    "        \"\"\"\n",
    "\n",
    "        npn = [pri, ari]\n",
    "        midaux = tuple(map(operator.add, pri, ari))\n",
    "        mid = tuple(map(lambda x: operator.truediv(x, 2), midaux))\n",
    "        dist_pri_ari = reduce(operator.add, pri+ari)\n",
    "\n",
    "        for xl in ss:\n",
    "            x = data.iloc[xl]\n",
    "            dist_mid_xl = numpy.linalg.norm(x - mid) \n",
    "            if dist_mid_xl <= dist_pri_ari:\n",
    "                npn.append(xl)\n",
    "\n",
    "        return npn\n",
    "    @staticmethod\n",
    "    def class_entropy(gama_mi, class_set):\n",
    "        gama_m = class_set.shape[0]\n",
    "        ret = 0\n",
    "\n",
    "        for index, c in class_set.iterrows():\n",
    "            ret += pd.Series.div((pd.Series.div(c, gama_mi) * pd.Series.div(c, gama_mi).apply(np.log10)), np.log10(gama_m))\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    @staticmethod\n",
    "    def selection_weight_formula(npn, w1, w2, r1, r2, mc, ma, mi, minorities):\n",
    "        \"\"\"formula (2) article\n",
    "            :param mc class c instances\n",
    "            :param ma majority class instance\n",
    "            :param mi minority class instance\n",
    "            :param minorities minorities classes\"\"\"\n",
    "\n",
    "        gama_ma = ma.shape[0]\n",
    "        gama_mi = mi.shape[0]\n",
    "        gama_c = mc.shape[0]\n",
    "\n",
    "        # Minority classes entropy\n",
    "        e_mi = Instance.class_entropy(gama_mi, minorities)\n",
    "\n",
    "        # Majority class entropy\n",
    "        e_ma = Instance.class_entropy(gama_mi, minorities)\n",
    "\n",
    "        overgeneralization_factor_aux = r1 * (gama_mi/ gama_c) + r2 * e_mi + w2 * (r1* gama_ma / gama_c + 2 * e_ma)\n",
    "        overgeneralization_factor = overgeneralization_factor_aux.apply(lambda x: x**2)\n",
    "        difficulty_factor = math.exp(-1 * (gama_c / gama_c + gama_ma + gama_mi))\n",
    "\n",
    "        return 1 / (overgeneralization_factor + w1 * difficulty_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random as rd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from instance import Instance\n",
    "\n",
    "class SMOM:\n",
    "    def __init__(self):\n",
    "        self.outstanding = []\n",
    "        self.trapped = []\n",
    "\n",
    "    @staticmethod\n",
    "    def kneigbor(data, xi, k, return_distance):\n",
    "        knn = NearestNeighbors(n_neighbors=k)\n",
    "        knn.fit(data.iloc[:, :data.shape[1]], data.iloc[:, -1])\n",
    "        return knn.kneighbors([xi], return_distance=return_distance)\n",
    "        \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def split_classes(data, minority_class):\n",
    "        c = data[data.iloc[:, -1] == minority_class]\n",
    "        not_c = data[data.iloc[:, -1] != minority_class]\n",
    "        return c, not_c\n",
    "\n",
    "    @staticmethod\n",
    "    def nearestK3Instances(xi, sc, k1, k2):\n",
    "        k3 = max([k1,k2])    \n",
    "\n",
    "        knn3 = NearestNeighbors(n_neighbors=k3)\n",
    "        knn3.fit(sc.iloc[:, :sc.shape[1]], sc.iloc[:, -1])\n",
    "        dist, k3neighbors = knn3.kneighbors([xi], return_distance=True)\n",
    "        \n",
    "        k3neighbors = k3neighbors.tolist()[0]\n",
    "        dist = dist.tolist()[0]\n",
    "\n",
    "        knn1 = NearestNeighbors(n_neighbors=k1)\n",
    "        knn1.fit(sc.iloc[:, :sc.shape[1]], sc.iloc[:, -1])\n",
    "        k1neighbors = knn1.kneighbors([xi], return_distance=False).tolist()[0]\n",
    "\n",
    "        # k3neighbors = knn.getNeighbors(sc, xi, k3)\n",
    "        # k1neighbors = knn.getNeighbors(sc, xi, k1)        \n",
    "        k1th = k1neighbors[0]\n",
    "        distance = numpy.linalg.norm(xi-k1th)\n",
    "    \n",
    "        return k3neighbors, dist, k1th, distance, k3\n",
    "\n",
    "    @staticmethod\n",
    "    def selection_weigth(data, outstandings, trapped_instances, k3, w1, w2, r1, r2, xi_fs_fd, minor):\n",
    "        \"\"\" Return a dict of weight for each instance\n",
    "            @:param trapped_instance list of type instance\n",
    "        \"\"\"\n",
    "        knn3 = NearestNeighbors(n_neighbors=k3)\n",
    "\n",
    "        sw = {}\n",
    "\n",
    "        for xi in trapped_instances:\n",
    "            index = data[data == xi].dropna(axis=0).index[0] \n",
    "\n",
    "            for xj in xi_fs_fd[index].keys():\n",
    "                xi_sw = {}\n",
    "\n",
    "                vis_xj = xi_fs_fd.get(xj, {})\n",
    "                # print(xi)\n",
    "                if (xj in outstandings) and (xi in xi_fs_fd[xj].keys()):\n",
    "                    xi_sw[xj] = 1 + w1/math.e              \n",
    "                elif (xj in xi_fs_fd.keys()) and (index in xi_fs_fd[xj].keys()) and (xj in sw.keys()) and (index in sw[xj].keys()):\n",
    "                    print(\"foi\")\n",
    "                    sw[index][xj] = sw[xj][index]\n",
    "                else:    \n",
    "                    v_xj = data.iloc[xj]\n",
    "                    smaller_distances = Instance.ss(xi, v_xj, xi_fs_fd[index]) \n",
    "                    npn = Instance.dpn(xi, v_xj, smaller_distances, data)\n",
    "                    \n",
    "                    vals = data[data.iloc[:, -1] == minor]\n",
    "                    ma_class, mi_class, minorities_class_set = SMOM.get_classes(data)\n",
    "                    ma = SMOM.get_class_set(data, ma_class)\n",
    "                    mi = SMOM.get_class_set(data, minor)\n",
    "\n",
    "                    minorities = data[(data.iloc[:, -1] == 1) | (data.iloc[:, -1] == 25) | (data.iloc[:, -1] == 2) | (data.iloc[:, -1] == 26) | (data.iloc[:, -1] == 29)]\n",
    "                    # minorities_class_set = {}\n",
    "                    ret = Instance.selection_weight_formula(npn, w1, w2, r1, r2, vals, ma, mi, minorities)\n",
    "                    #print(ret)\n",
    "                    xi_sw[xj] = ret\n",
    "               \n",
    "            sw[index] = xi_sw\n",
    "            print(\"foi aqui\")\n",
    "        \n",
    "        # return weightDict\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def filterOutstanding(sc, cl, minor):\n",
    "        outstanding = []\n",
    "        trapped = []\n",
    "        index_trapped = []\n",
    "        \n",
    "        for instanceIndex in range(sc[sc.iloc[:, -1] == minor].shape[0]):\n",
    "            #print(instanceIndex)\n",
    "            instance = sc.iloc[instanceIndex]\n",
    "            if cl[instanceIndex] != 0:\n",
    "                outstanding.append(instance)\n",
    "            else:\n",
    "                trapped.append(instance)\n",
    "                index_trapped.appens(instanceIndex)\n",
    "                \n",
    "        return (outstanding, trapped, index_trapped)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_classes(data):\n",
    "        # Get majority class\n",
    "        ma = data.iloc[:, -1].value_counts().idxmax()\n",
    "\n",
    "        # Get minority class\n",
    "        mi = data.iloc[:, -1].value_counts().idxmin()\n",
    "\n",
    "        # Get minority classes set\n",
    "        mi_aux = data.iloc[:, -1].value_counts() == data.iloc[:, -1].value_counts().min()\n",
    "        mi_set = mi_aux[mi_aux == True]\n",
    "        return ma, mi, mi_set\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_class_set(data, class_name):\n",
    "        # print(\">>> \" + str(data.iloc[:, -1].size) )\n",
    "        # print(class_name)\n",
    "        return data[data.iloc[:, -1] == class_name]\n",
    "\n",
    "    def generate_synthetic_instances(self, sc, g):\n",
    "        xj = 0\n",
    "        si = []\n",
    "        for times in range(g):\n",
    "            for i in sc:\n",
    "                if i in self.trapped:\n",
    "                    xj = i.get_neighbor_high_weight()\n",
    "                else:\n",
    "                    xj = rd.choice(i.get_nk1())\n",
    "\n",
    "                diff = (xj - i)\n",
    "                gama = [rd.randrange(0, 2) for i in range(len(xj))]\n",
    "                new_instance = i + diff.dot(gama)\n",
    "\n",
    "                si.append(new_instance)\n",
    "\n",
    "        return si\n",
    "\n",
    "    @staticmethod\n",
    "    def get_g_for_each_xi(xi, zeta, sc):\n",
    "        g, remainder = SMOM.get_floor_remainder(zeta, len(sc))\n",
    "\n",
    "        if xi == sc[-1]: ##\n",
    "            return g+remainder\n",
    "        else:\n",
    "            return g\n",
    "\n",
    "    @staticmethod\n",
    "    def get_floor_remainder(zeta, sc_size):\n",
    "        if (zeta%sc_size) == 0:\n",
    "            return zeta/sc_size, 0\n",
    "        else:\n",
    "            g_for_each_xi = int(math.floor(zeta/sc_size))\n",
    "            remainder = zeta%sc_size\n",
    "            return g_for_each_xi, remainder\n",
    "\n",
    "    @staticmethod\n",
    "    def nearEnemy(xi, others, k3, distance, neighbors, neighbors_distance):\n",
    "        knn3 = NearestNeighbors(n_neighbors=k3)\n",
    "        knn3.fit(others.iloc[:, :others.shape[1]], others.iloc[:, -1])\n",
    "        dist, k3neighbors = knn3.kneighbors([xi], return_distance=True)\n",
    "        \n",
    "        k3neighbors = k3neighbors.tolist()[0]\n",
    "        dist = dist.tolist()[0]\n",
    "\n",
    "        fs = []\n",
    "        fd = []\n",
    "        for i in range(len(dist)):\n",
    "            if dist[i] < distance:\n",
    "                fs.append(k3neighbors[i])\n",
    "                fd.append(dist[i])\n",
    "\n",
    "        fs = fs + neighbors\n",
    "        fd = fd + neighbors_distance\n",
    "        \n",
    "        return k3neighbors, fs, fd        \n",
    "        \n",
    "    @staticmethod\n",
    "    def k2_neighbors(data, k3_neighbor, k3_enemy, xi, k2, k3):\n",
    "        frames = numpy.concatenate([k3_neighbor, k3_enemy])\n",
    "        #print(frames)\n",
    "        knn = NearestNeighbors(n_neighbors=k2)\n",
    "        knn.fit(data.iloc[frames, :len(frames)], data.iloc[frames, -1])\n",
    "        return knn.kneighbors([xi], return_distance=False).tolist()[0] \n",
    "\n",
    "    @staticmethod\n",
    "    def probability_distribution(xi, index_xi, k1neighbors, w1, fs_fd, data): # the return is a list of probabilities with the ormat [xj, xipj], xj is the instance from a different class and xipj it probability\n",
    "        xipj = [] \n",
    "        flag = True\n",
    "        weightlist = []\n",
    "\n",
    "        for xj in k1neighbors: #k1neighbors should follows the same format of the return of this method: i.e: [[[0.00078,0.9475,0.084,0.00009,\"g\"], 0.002568],[[0.045,0.0645,0.084,0.00009,\"t\"], 0.00568]]  while xi is a simple instance without the distance\n",
    "            weightlist.append(fs_fs.get(xi))\n",
    "            smaller_distances= Instance.ss(xi, xj, fs_fd)\n",
    "            npn = Instance.dpn(xi, xj, smaller_distances, data)\n",
    "                \n",
    "            for element in npn:\n",
    "                print(element)\n",
    "                if element[-2][-1] == xi[-1]:\n",
    "                    flag = False\n",
    "                    break\n",
    "                \n",
    "            if(xj[-2][-1] != xi[-1]):\n",
    "                    xipj.append([xj,xi.get_neighbor_weight(xj)/(math.sum(weightlist))])\n",
    "\n",
    "        if flag:\n",
    "            weight = 1 + (w1/math.e)\n",
    "            k1neighbors.append([xi, weight])\n",
    "            \n",
    "        return xipj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-97f360057240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNbdos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbdos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrTh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnTh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0moutstandings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrappeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_trapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterOutstanding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;31m#5.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection_weigth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutstandings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrappeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi_fs_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from SMOM import SMOM\n",
    "from nbdos import Nbdos\n",
    "import pandas as pd\n",
    "# import main2\n",
    "\n",
    "data = pd.read_csv(\"data/data.csv\", header=None)\n",
    "data = data.iloc[:, 1:].head(500)\n",
    "#min_class = data.iloc[:, -1].value_counts().min()\n",
    "min_class = 16 #classe com 67 instancias\n",
    "k1 = 12\n",
    "k2 = 8\n",
    "rTh = 5/8\n",
    "nTh = 10\n",
    "k = 2\n",
    "w1 = 0.2\n",
    "w2 = 0.5\n",
    "r1 = 1/3\n",
    "r2 = 0.2\n",
    "\n",
    "#1. Dividindo dados entre classe minoriataria e outros\n",
    "sc, others =  SMOM.split_classes(data, min_class) \n",
    "\n",
    "xi_fs_fd = {}\n",
    "\n",
    "#2.\n",
    "for index, xi in sc.iterrows():\n",
    "    fs_fd = {}\n",
    "# 2.1)\n",
    "    k3neighbors, neighbors_distance, k1th, distance, k3 = SMOM.nearestK3Instances(xi, sc, k1, k2)\n",
    "# 2.2)\n",
    "    k3EnemyNeighbor, fs, fd = SMOM.nearEnemy(xi, others, k3, distance, k3neighbors, neighbors_distance)\n",
    "# 2.3)\n",
    "    k2_neighbors = SMOM.k2_neighbors(data, k3neighbors, k3EnemyNeighbor, xi, k2, k3)\n",
    "    \n",
    "    for i in range(len(fs)):\n",
    "        fs_fd[fs[i]] = fd[i]\n",
    "    xi_fs_fd[index] = fs_fd\n",
    "#3.\n",
    "cl = Nbdos().nbdos(data, sc, k2, k2_neighbors, rTh, nTh)\n",
    "#4.\n",
    "outstandings, trappeds, index_trapped = SMOM.filterOutstanding(sc, cl, min_class)       \n",
    "#5.\n",
    "dic = SMOM.selection_weigth(data, outstandings, trappeds, k3, w1, w2, r1, r2, xi_fs_fd, min_class)\n",
    "\n",
    "#6.\n",
    "\n",
    "\n",
    "\n",
    "#  6.1)\n",
    "#  6.2)\n",
    "\n",
    "\n",
    "#7.\n",
    "\n",
    "#8.\n",
    "# instance\n",
    "#   8.1.\n",
    "#   8.2\n",
    "#   8.3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trappeds)):\n",
    "    \n",
    "    k1neighbors = SMOM.kneigbor(data, trappeds[i], k1, False)\n",
    "    xipj = SMOM.probability_distribution(xi, index_trapped, k1neighbors, w1, data, xi_fs_fd.get(index_trapped))\n",
    "    print(xipj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(sc[sc.iloc[:, -1] == 16].shape[0]):\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def a():\n",
    "    return  1, 2, 3\n",
    "\n",
    "c,d,e = a()\n",
    "e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
